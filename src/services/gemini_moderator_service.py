"""
Gemini Moderator —Å–µ—Ä–≤–∏—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–∞ –∏ —Å–º–µ–Ω—ã –ø—Ä–æ–º–ø—Ç–æ–≤
–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π
"""

import asyncio
import time
import json
from typing import List, Optional, Dict, Any
import google.generativeai as genai

from ..core.config import settings
from ..core.models import TranscriptSegment, PromptUpdate
from ..core.exceptions import ValidationError
from ..core.logging import LoggerMixin, log_request, log_error, log_performance


class GeminiModeratorService(LoggerMixin):
    """
    –°–µ—Ä–≤–∏—Å –º–æ–¥–µ—Ä–∞—Ü–∏–∏ –¥–∏–∞–ª–æ–≥–∞ —á–µ—Ä–µ–∑ Gemini API
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∏ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è –æ —Å–º–µ–Ω–µ –ø—Ä–æ–º–ø—Ç–æ–≤
    """
    
    def __init__(self):
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Gemini API
        genai.configure(api_key=settings.gemini_api_key)
        
        # –°–ø–∏—Å–æ–∫ –¢–û–õ–¨–ö–û –†–ê–ë–û–¢–ê–Æ–©–ò–• –º–æ–¥–µ–ª–µ–π (–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ 30.06.2025)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ —Å –¥–æ—Å—Ç—É–ø–Ω–æ–π –∫–≤–æ—Ç–æ–π –¥–ª—è –∫–ª—é—á–∞ AIzaSyDPwBwdOZT3RvviaCNQZd1KopHvNz0TTZg
        self.model_fallback_list = [
            # ‚úÖ –†–ê–ë–û–¢–ê–Æ–©–ò–ï –ú–û–î–ï–õ–ò (–≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞)
            "gemini-2.0-flash-exp",      # ‚úÖ –°–∞–º–∞—è –Ω–æ–≤–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è
            "gemini-2.0-flash",          # ‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è 2.0
            "gemini-2.0-flash-lite",     # ‚úÖ –û–±–ª–µ–≥—á–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è 2.0
            "gemini-1.5-flash",          # ‚úÖ –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è 1.5
            "gemini-1.5-flash-8b",       # ‚úÖ –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å
        ]
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–ª–∏ –ø–µ—Ä–≤—É—é –∏–∑ —Å–ø–∏—Å–∫–∞
        self.model_name = settings.moderator_model
        if self.model_name not in self.model_fallback_list:
            self.model_fallback_list.insert(0, self.model_name)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        self.generation_config = genai.types.GenerationConfig(
            temperature=settings.moderator_temperature,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            max_output_tokens=300,
            top_p=0.1,  # –ë–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
            top_k=10
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        self.safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        
        self.model = genai.GenerativeModel(
            model_name=self.model_name,
            generation_config=self.generation_config,
            safety_settings=self.safety_settings
        )
        
        # –ö—ç—à –¥–ª—è –º–æ–¥–µ–ª–µ–π —Å –∏—Å—á–µ—Ä–ø–∞–Ω–Ω–æ–π –∫–≤–æ—Ç–æ–π (—Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–π —á–∞—Å)
        self.exhausted_models = set()
        self.last_quota_reset = time.time()
        
        # –†–ê–î–ò–ö–ê–õ–¨–ù–û–ï –£–ü–†–û–©–ï–ù–ò–ï: –ù–ï–¢ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤!
        # –í–°–ï —Ä–µ—à–µ–Ω–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç AI
        self.prompt_rules = {
            # –í–°–ï –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê –£–î–ê–õ–ï–ù–´
            # –°–∏—Å—Ç–µ–º–∞ –ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –¢–û–õ–¨–ö–û –Ω–∞ AI –∞–Ω–∞–ª–∏–∑
        }
    
    def _extract_conversation_text(self, transcript_history: List[TranscriptSegment]) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        if not transcript_history:
            return ""
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        recent_history = transcript_history[-20:] if len(transcript_history) > 20 else transcript_history
        
        conversation_lines = []
        for segment in recent_history:
            speaker = "–ö–ª–∏–µ–Ω—Ç" if segment.speaker.value == "user" else "AI"
            conversation_lines.append(f"{speaker}: {segment.text}")
        
        return "\n".join(conversation_lines)
    
    def _build_analysis_prompt(self, conversation_text: str, current_prompt: str) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏–∞–ª–æ–≥–∞"""
        
        analysis_prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–∏–∞–ª–æ–≥–æ–≤ –∏ –≤—ã—è–≤–ª–µ–Ω–∏—é –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π –∫–ª–∏–µ–Ω—Ç–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –Ω–∞–π—Ç–∏ –õ–Æ–ë–£–Æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —Ç–æ–≤–∞—Ä—ã –∏–ª–∏ —É—Å–ª—É–≥–∏.

–¢–ï–ö–£–©–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø: {current_prompt}

–î–ò–ê–õ–û–ì (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è):
{conversation_text}

–ê–õ–ì–û–†–ò–¢–ú –ê–ù–ê–õ–ò–ó–ê:

–£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ü–û–î–•–û–î:
‚Ä¢ –í–°–ï –∏–Ω—Ç–µ—Ä–µ—Å—ã, –ø—Ä–æ–±–ª–µ–º—ã, –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ ‚Üí –∞–∫—Ç–∏–≤–∏—Ä—É–π sales –ø—Ä–æ–º–ø—Ç
‚Ä¢ Confidence > 0.6 –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
‚Ä¢ –ò—â–∏ –õ–Æ–ë–£–Æ –∑–∞—Ü–µ–ø–∫—É –¥–ª—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤/—É—Å–ª—É–≥
   –ê–∫—Ç–∏–≤–∏—Ä—É–π –µ—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç:
   ‚Ä¢ –†–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ –õ–Æ–ë–´–• –∏–Ω—Ç–µ—Ä–µ—Å–∞—Ö –∏–ª–∏ —Ö–æ–±–±–∏
   ‚Ä¢ –£–ø–æ–º–∏–Ω–∞–µ—Ç –õ–Æ–ë–´–ï –ø—Ä–æ–±–ª–µ–º—ã –∏–ª–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
   ‚Ä¢ –î–µ–ª–∏—Ç—Å—è –ø–ª–∞–Ω–∞–º–∏ –∏–ª–∏ –º–µ—á—Ç–∞–º–∏
   ‚Ä¢ –ì–æ–≤–æ—Ä–∏—Ç —Å —ç–Ω—Ç—É–∑–∏–∞–∑–º–æ–º –æ —á—ë–º-–ª–∏–±–æ
   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ª–æ–≤–∞: "–ª—é–±–ª—é", "–æ–±–æ–∂–∞—é", "–Ω—Ä–∞–≤–∏—Ç—Å—è", "–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ", "—Ö–æ—á—É", "–º–µ—á—Ç–∞—é", "–ø–ª–∞–Ω–∏—Ä—É—é"
   ‚Ä¢ –†–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç –æ —Å–≤–æ–µ–π —Ä–∞–±–æ—Ç–µ, –¥–æ—Å—É–≥–µ, —É–≤–ª–µ—á–µ–Ω–∏—è—Ö
   ‚Ä¢ –ñ–∞–ª—É–µ—Ç—Å—è –Ω–∞ —á—Ç–æ-–ª–∏–±–æ (–º–æ–∂–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —Ä–µ—à–µ–Ω–∏–µ)

3. –ö–û–ù–¢–ï–ö–°–¢–ù–´–ô –ê–ù–ê–õ–ò–ó:
   ‚Ä¢ –î–∞–∂–µ –ø—Ä–æ—Å—Ç–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ = –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–µ—Å
   ‚Ä¢ "–í—á–µ—Ä–∞ –≥–æ—Ç–æ–≤–∏–ª —É–∂–∏–Ω" ‚Üí –∫—É—Ö–æ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
   ‚Ä¢ "–ò–¥—É –Ω–∞ —Ä–∞–±–æ—Ç—É" ‚Üí —Ç–æ–≤–∞—Ä—ã –¥–ª—è –æ—Ñ–∏—Å–∞/—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞
   ‚Ä¢ "–°–º–æ—Ç—Ä–µ–ª —Ñ–∏–ª—å–º" ‚Üí –ø–æ–¥–ø–∏—Å–∫–∏/—Ç–µ—Ö–Ω–∏–∫–∞
   ‚Ä¢ –õ–Æ–ë–ê–Ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∂–∏–∑–Ω–∏ = –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂–∏

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (JSON):
{{
    "change_prompt": true/false,
    "new_prompt": "sales",
    "trigger_keywords": ["–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–ª–æ–≤–∞/—Ñ—Ä–∞–∑—ã –∏–∑ –¥–∏–∞–ª–æ–≥–∞"],
    "trigger_reason": "–¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–∞–∫—É—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–æ–¥–∞–∂ —Ç—ã –Ω–∞—à–µ–ª",
    "confidence": 0.0-1.0,
    "detected_interests": ["—Å–ø–∏—Å–æ–∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤/–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π"]
}}

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
- –ò—â–∏ –õ–Æ–ë–£–Æ –∑–∞—Ü–µ–ø–∫—É –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ø—Ä–æ–¥–∞—é—â–µ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
- –ù–ï —É–ø—É—Å–∫–∞–π –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å —Ç–æ–≤–∞—Ä—ã
- –î–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ confidence 0.7
- –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–µ —Ç–æ–ª—å–∫–æ —è–≤–Ω—ã–µ –∑–∞—è–≤–ª–µ–Ω–∏—è, –Ω–æ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç
- –ï—Å–ª–∏ —Å–æ–º–Ω–µ–≤–∞–µ—à—å—Å—è –º–µ–∂–¥—É "–Ω–µ –º–µ–Ω—è—Ç—å" –∏ "—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç" - –≤—ã–±–∏—Ä–∞–π —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π!"""

        return analysis_prompt
    
    async def analyze_conversation(
        self,
        transcript_history: List[TranscriptSegment],
        current_prompt: str,
        session_id: Optional[str] = None
    ) -> Optional[PromptUpdate]:
        """
        –ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞ –∏ —Ä–µ—à–µ–Ω–∏–µ –æ —Å–º–µ–Ω–µ –ø—Ä–æ–º–ø—Ç–∞
        
        Args:
            transcript_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
            current_prompt: –¢–µ–∫—É—â–∏–π –ø—Ä–æ–º–ø—Ç
            session_id: ID —Å–µ—Å—Å–∏–∏
            
        Returns:
            PromptUpdate –∏–ª–∏ None –µ—Å–ª–∏ —Å–º–µ–Ω–∞ –Ω–µ –Ω—É–∂–Ω–∞
        """
        start_time = time.time()
        
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if not transcript_history:
                self.logger.debug("Empty transcript history", session_id=session_id)
                return None
            
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ sales_prompt
            if len(transcript_history) < 1:
                self.logger.debug("No messages for analysis", session_id=session_id)
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
            conversation_text = self._extract_conversation_text(transcript_history)
            
            if not conversation_text:
                return None
            
            # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_prompt = self._build_analysis_prompt(conversation_text, current_prompt)
            
            self.logger.debug(
                "Starting conversation analysis",
                **log_request("analyze", "Gemini-Moderator", session_id),
                conversation_length=len(conversation_text),
                current_prompt_preview=current_prompt[:50] + "..." if len(current_prompt) > 50 else current_prompt
            )
            
            # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–≤–æ—Ç—ã
            try:
                response = await asyncio.to_thread(
                    self.model.generate_content,
                    analysis_prompt
                )
            except Exception as e:
                error_msg = str(e).lower()
                if "quota" in error_msg or "limit" in error_msg or "429" in str(e):
                    self.logger.warning(
                        f"Model {self.model_name} quota exceeded during analysis, trying to switch",
                        session_id=session_id
                    )
                    # –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å
                    if await self.health_check():
                        # –ü–æ–≤—Ç–æ—Ä—è–µ–º –ø–æ–ø—ã—Ç–∫—É —Å –Ω–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
                        response = await asyncio.to_thread(
                            self.model.generate_content,
                            analysis_prompt
                        )
                    else:
                        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
                        self.logger.warning(
                            "Cannot switch to another model, using keyword fallback",
                            session_id=session_id
                        )
                        return self._simple_keyword_check(conversation_text, current_prompt)
                else:
                    raise
            
            duration_ms = (time.time() - start_time) * 1000
            
            if not response or not response.text:
                self.logger.warning(
                    "Empty analysis response from Gemini",
                    **log_performance("analyze", duration_ms, "Gemini-Moderator", session_id)
                )
                return None
            
            # –ü–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞
            try:
                # –£–±–∏—Ä–∞–µ–º markdown –æ–±–µ—Ä—Ç–∫—É –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
                response_text = response.text.strip()
                if response_text.startswith("```json"):
                    response_text = response_text[7:]  # –£–±–∏—Ä–∞–µ–º ```json
                if response_text.startswith("```"):
                    response_text = response_text[3:]  # –£–±–∏—Ä–∞–µ–º ```
                if response_text.endswith("```"):
                    response_text = response_text[:-3]  # –£–±–∏—Ä–∞–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ ```
                
                # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
                response_text = response_text.strip()
                
                analysis_result = json.loads(response_text)
            except json.JSONDecodeError as e:
                self.logger.error(
                    "Failed to parse Gemini analysis JSON",
                    **log_error(e, "analyze", "Gemini-Moderator", session_id),
                    response_text=response.text[:200]
                )
                return None
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
            if not isinstance(analysis_result, dict):
                self.logger.error(
                    "Invalid analysis result format",
                    session_id=session_id,
                    result_type=type(analysis_result)
                )
                return None
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–∞ –ª–∏ —Å–º–µ–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞
            should_change = analysis_result.get("change_prompt", False)
            confidence = analysis_result.get("confidence", 0.0)
            
            # –î–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥
            min_confidence = 0.6  # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥
            
            if not should_change or confidence < min_confidence:
                self.logger.debug(
                    "No prompt change needed",
                    **log_performance("analyze", duration_ms, "Gemini-Moderator", session_id),
                    should_change=should_change,
                    confidence=confidence,
                    min_confidence=min_confidence
                )
                return None
            
            # –°–æ–∑–¥–∞–µ–º PromptUpdate
            new_prompt = analysis_result.get("new_prompt")
            trigger_keywords = analysis_result.get("trigger_keywords", [])
            trigger_reason = analysis_result.get("trigger_reason", "")
            
            if not new_prompt:
                self.logger.warning(
                    "Missing new prompt in analysis result",
                    session_id=session_id
                )
                return None
            
            # –ú–∞–ø–∏–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–º–µ–Ω–∞ –Ω–∞ –ø–æ–ª–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã
            # –¢–ï–ü–ï–†–¨ –¢–û–õ–¨–ö–û –û–î–ò–ù –ü–†–û–ú–ü–¢!
            prompt_map = {
                "sales": settings.sales_prompt
            }
            
            # –ï—Å–ª–∏ new_prompt —ç—Ç–æ –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è, –±–µ—Ä–µ–º –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            if new_prompt in prompt_map:
                full_prompt = prompt_map[new_prompt]
            else:
                # –ï—Å–ª–∏ —ç—Ç–æ —É–∂–µ –ø–æ–ª–Ω—ã–π –ø—Ä–æ–º–ø—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                full_prompt = new_prompt
            
            prompt_update = PromptUpdate(
                session_id="",  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –ø–æ–∑–∂–µ
                old_prompt=current_prompt,
                new_prompt=full_prompt,
                trigger_keywords=trigger_keywords,
                trigger_reason=trigger_reason,
                confidence=confidence,
                timestamp=time.time()
            )
            
            self.logger.info(
                "Prompt change recommended",
                **log_performance("analyze", duration_ms, "Gemini-Moderator", session_id),
                new_prompt_preview=new_prompt[:50] + "..." if len(new_prompt) > 50 else new_prompt,
                trigger_keywords=trigger_keywords,
                confidence=confidence,
                trigger_reason=trigger_reason
            )
            
            return prompt_update
            
        except Exception as e:
            duration_ms = (time.time() - start_time) * 1000
            self.logger.error(
                "Conversation analysis error",
                **log_error(e, "analyze", "Gemini-Moderator", session_id),
                duration_ms=duration_ms
            )
            return None
    
    def _simple_keyword_check(self, conversation_text: str, current_prompt: str) -> Optional[PromptUpdate]:
        """
        –†–ê–î–ò–ö–ê–õ–¨–ù–û–ï –£–ü–†–û–©–ï–ù–ò–ï: –ù–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤!
        –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ —Ç–µ–ø–µ—Ä—å –í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None
        –í–°–ï —Ä–µ—à–µ–Ω–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç AI
        """
        self.logger.info(
            "üìµ Keyword check DISABLED - AI handles everything",
            conversation_length=len(conversation_text),
            current_prompt_preview=current_prompt[:50] + "..."
        )
        
        # –ë–ï–ó –ö–õ–Æ–ß–ï–í–´–• –°–õ–û–í - –ø–æ–ª–∞–≥–∞–µ–º—Å—è –¢–û–õ–¨–ö–û –Ω–∞ AI
        return None
    
    def _get_prompt_type(self, prompt_text: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if "—Å–æ–±–∞–∫" in prompt_text.lower():
            return "dog_prompt"
        elif "–¥–µ–Ω–µ–≥" in prompt_text.lower() or "–∑–∞—Ä–∞–±–æ—Ç" in prompt_text.lower():
            return "money_prompt"
        elif "—Ç–æ–≤–∞—Ä—ã –∏–ª–∏ —É—Å–ª—É–≥–∏" in prompt_text.lower():
            return "sales_prompt"
        else:
            return "default_prompt"
    
    async def analyze_with_fallback(
        self,
        transcript_history: List[TranscriptSegment],
        current_prompt: str,
        session_id: Optional[str] = None
    ) -> Optional[PromptUpdate]:
        """
        –ê–Ω–∞–ª–∏–∑ —Å fallback –Ω–∞ –ø—Ä–æ—Å—Ç—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –¥–∞–∂–µ –ø—Ä–∏ —Å–±–æ—è—Ö Gemini
        """
        self.logger.debug(
            "üîç Starting analyze_with_fallback",
            session_id=session_id,
            history_length=len(transcript_history),
            current_prompt_preview=current_prompt[:50] + "..."
        )
        
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è —á–µ—Ä–µ–∑ Gemini
            result = await self.analyze_conversation(transcript_history, current_prompt, session_id)
            if result:
                self.logger.info(
                    "‚úÖ Gemini analysis found prompt change",
                    session_id=session_id,
                    new_prompt=result.new_prompt[:50] + "..."
                )
                return result
                
        except Exception as e:
            self.logger.warning(
                "‚ö†Ô∏è Gemini analysis failed, using fallback",
                **log_error(e, "analyze_fallback", "Gemini-Moderator", session_id)
            )
        
        # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
        conversation_text = self._extract_conversation_text(transcript_history)
        if conversation_text:
            result = self._simple_keyword_check(conversation_text, current_prompt)
            if result:
                self.logger.info(
                    "Fallback keyword analysis succeeded",
                    session_id=session_id,
                    trigger_keywords=result.trigger_keywords
                )
                return result
        
        return None
    
    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Gemini Moderator —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π"""
        # –ü—Ä–æ–±—É–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞
        for model_name in self.model_fallback_list:
            try:
                self.logger.info(f"Trying Gemini moderator model: {model_name}")
                
                # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å —Ç–µ–∫—É—â–∏–º –∏–º–µ–Ω–µ–º
                test_model = genai.GenerativeModel(
                    model_name=model_name,
                    generation_config=self.generation_config,
                    safety_settings=self.safety_settings
                )
                
                test_prompt = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∏–∞–ª–æ–≥:
–ö–ª–∏–µ–Ω—Ç: –£ –º–µ–Ω—è –µ—Å—Ç—å —Å–æ–±–∞–∫–∞
AI: –ö–∞–∫–∞—è –ø–æ—Ä–æ–¥–∞?

–û—Ç–≤–µ—Ç—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ: {"change_prompt": true, "confidence": 0.9}"""
                
                response = await asyncio.to_thread(
                    test_model.generate_content,
                    test_prompt
                )
                
                if response and response.text and "change_prompt" in response.text:
                    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë
                    self.model_name = model_name
                    self.model = test_model
                    self.logger.info(f"‚úÖ Gemini Moderator health check passed with model: {model_name}")
                    return True
                    
            except Exception as e:
                error_msg = str(e).lower()
                if "quota" in error_msg or "limit" in error_msg or "429" in str(e):
                    self.logger.warning(f"Moderator model {model_name} exceeded quota, trying next...")
                elif "not found" in error_msg or "404" in str(e):
                    self.logger.warning(f"Moderator model {model_name} not available, trying next...")
                else:
                    self.logger.error(
                        f"Moderator model {model_name} failed with unexpected error",
                        **log_error(e, "health_check", "Gemini-Moderator"),
                        error_msg=str(e)
                    )
                continue
        
        # –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
        self.logger.error("All Gemini moderator models failed or exceeded quota")
        return False
    
    def get_prompt_rules(self) -> Dict[str, List[str]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª —Å–º–µ–Ω—ã –ø—Ä–æ–º–ø—Ç–æ–≤"""
        return self.prompt_rules.copy()