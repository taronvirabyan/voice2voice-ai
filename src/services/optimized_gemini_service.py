"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Gemini —Å–µ—Ä–≤–∏—Å –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π —Ä–∞–±–æ—Ç—ã
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏ —Å –æ–¥–Ω–∏–º API –∫–ª—é—á–æ–º
"""

import asyncio
import time
from typing import List, Dict, Optional, Any
import google.generativeai as genai

from ..core.config import settings
from ..core.models import TranscriptSegment, MessageRole
from ..core.exceptions import ValidationError
from ..core.logging import LoggerMixin, log_request, log_error, log_performance


class OptimizedGeminiService(LoggerMixin):
    """
    –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Gemini API
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ Voice AI –∏ Moderator –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
    """
    
    # –°–ø–∏—Å–æ–∫ –¢–û–õ–¨–ö–û –†–ê–ë–û–¢–ê–Æ–©–ò–• –º–æ–¥–µ–ª–µ–π (–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ 30.06.2025)
    WORKING_MODELS = [
        "gemini-2.0-flash-exp",      # ‚úÖ –°–∞–º–∞—è –Ω–æ–≤–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è
        "gemini-2.0-flash",          # ‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è 2.0
        "gemini-2.0-flash-lite",     # ‚úÖ –û–±–ª–µ–≥—á–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è 2.0
        "gemini-1.5-flash",          # ‚úÖ –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è 1.5
        "gemini-1.5-flash-8b",       # ‚úÖ –ö–æ–º–ø–∞–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å
    ]
    
    def __init__(self):
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Gemini API —Å –µ–¥–∏–Ω—ã–º –∫–ª—é—á–æ–º
        genai.configure(api_key=settings.gemini_api_key)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é —Ä–∞–±–æ—Ç–∞—é—â—É—é –º–æ–¥–µ–ª—å
        self.current_model_index = 0
        self.model_name = self.WORKING_MODELS[self.current_model_index]
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –¥–∏–∞–ª–æ–≥–∞
        self.generation_config = genai.types.GenerationConfig(
            temperature=settings.temperature,
            max_output_tokens=settings.max_tokens,
            top_p=0.8,
            top_k=40
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –º–æ–¥–µ—Ä–∞—Ü–∏–∏ (–±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ)
        self.moderation_config = genai.types.GenerationConfig(
            temperature=0.3,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            max_output_tokens=300,
            top_p=0.1,
            top_k=10
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (—Ä–∞–∑—Ä–µ—à–∞–µ–º –≤—Å–µ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã)
        self.safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª–∏
        self._create_models()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        self.request_count = 0
        self.success_count = 0
        self.model_switches = 0
        self.last_switch_time = None
        
        self.logger.info(
            "‚úÖ Optimized Gemini Service initialized",
            model=self.model_name,
            available_models=len(self.WORKING_MODELS)
        )
    
    def _create_models(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –¥–∏–∞–ª–æ–≥–∞ –∏ –º–æ–¥–µ—Ä–∞—Ü–∏–∏"""
        self.dialogue_model = genai.GenerativeModel(
            model_name=self.model_name,
            generation_config=self.generation_config,
            safety_settings=self.safety_settings
        )
        
        self.moderation_model = genai.GenerativeModel(
            model_name=self.model_name,
            generation_config=self.moderation_config,
            safety_settings=self.safety_settings
        )
    
    async def _switch_to_next_model(self) -> bool:
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å"""
        if self.current_model_index >= len(self.WORKING_MODELS) - 1:
            self.logger.error("All models exhausted!")
            return False
        
        self.current_model_index += 1
        self.model_name = self.WORKING_MODELS[self.current_model_index]
        self.model_switches += 1
        self.last_switch_time = time.time()
        
        self.logger.info(
            f"üîÑ Switching to next model: {self.model_name}",
            model_index=self.current_model_index,
            total_switches=self.model_switches
        )
        
        # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª–∏ —Å –Ω–æ–≤—ã–º –∏–º–µ–Ω–µ–º
        self._create_models()
        return True
    
    async def _execute_with_fallback(
        self,
        model: Any,
        prompt: str,
        operation_name: str,
        session_id: Optional[str] = None
    ) -> Optional[str]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π"""
        start_time = time.time()
        self.request_count += 1
        
        while self.current_model_index < len(self.WORKING_MODELS):
            try:
                self.logger.debug(
                    f"Attempting {operation_name} with {self.model_name}",
                    session_id=session_id
                )
                
                response = await asyncio.to_thread(
                    model.generate_content,
                    prompt
                )
                
                if response and response.text:
                    duration_ms = (time.time() - start_time) * 1000
                    self.success_count += 1
                    
                    self.logger.info(
                        f"‚úÖ {operation_name} successful",
                        model=self.model_name,
                        duration_ms=duration_ms,
                        session_id=session_id
                    )
                    
                    return response.text.strip()
                
            except Exception as e:
                error_msg = str(e).lower()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ –∫–≤–æ—Ç—ã
                if any(indicator in error_msg for indicator in ["quota", "limit", "429", "resourceexhausted"]):
                    self.logger.warning(
                        f"Model {self.model_name} quota exceeded",
                        error=str(e),
                        session_id=session_id
                    )
                    
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å
                    if not await self._switch_to_next_model():
                        break
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏
                    if operation_name.startswith("dialogue"):
                        model = self.dialogue_model
                    else:
                        model = self.moderation_model
                    
                    continue
                else:
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ - –ª–æ–≥–∏—Ä—É–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
                    self.logger.error(
                        f"{operation_name} error",
                        error=str(e),
                        model=self.model_name,
                        session_id=session_id
                    )
                    return None
        
        # –ï—Å–ª–∏ –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
        self.logger.error(
            f"All models exhausted for {operation_name}",
            total_attempts=self.current_model_index + 1,
            session_id=session_id
        )
        return None
    
    async def generate_dialogue_response(
        self,
        user_message: str,
        current_prompt: str,
        conversation_history: List[TranscriptSegment],
        session_id: Optional[str] = None
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –¥–∏–∞–ª–æ–≥–∞"""
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context = self._build_dialogue_context(
            user_message, current_prompt, conversation_history
        )
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å fallback
        response = await self._execute_with_fallback(
            self.dialogue_model,
            context,
            "dialogue_generation",
            session_id
        )
        
        if response:
            return self._postprocess_dialogue_response(response)
        else:
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –Ω–µ–ø–æ–ª–∞–¥–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
    
    async def analyze_for_prompt_change(
        self,
        transcript_history: List[TranscriptSegment],
        current_prompt: str,
        session_id: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è —Å–º–µ–Ω—ã –ø—Ä–æ–º–ø—Ç–∞"""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        conversation_text = self._extract_conversation_text(transcript_history)
        if not conversation_text:
            return None
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        keyword_result = self._check_keywords(conversation_text, current_prompt)
        if keyword_result:
            return keyword_result
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º AI –∞–Ω–∞–ª–∏–∑
        analysis_prompt = self._build_moderation_prompt(conversation_text, current_prompt)
        
        response = await self._execute_with_fallback(
            self.moderation_model,
            analysis_prompt,
            "moderation_analysis",
            session_id
        )
        
        if response:
            return self._parse_moderation_response(response)
        
        return None
    
    def _build_dialogue_context(
        self,
        user_message: str,
        current_prompt: str,
        conversation_history: List[TranscriptSegment]
    ) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –¥–∏–∞–ª–æ–≥–∞"""
        context = f"""–¢—ã - –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫ –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –¥–∏–∞–ª–æ–≥–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–¢–ï–ö–£–©–ê–Ø –ó–ê–î–ê–ß–ê: {current_prompt}

–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
2. –ò—Å–ø–æ–ª—å–∑—É–π —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã–π —Å—Ç–∏–ª—å
3. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–º (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
4. –°–ª–µ–¥—É–π —Ç–µ–∫—É—â–µ–π –∑–∞–¥–∞—á–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ
5. –ë—É–¥—å –∏—Å–∫—Ä–µ–Ω–Ω–µ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω –≤ —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–µ

–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        recent = conversation_history[-10:] if len(conversation_history) > 10 else conversation_history
        for segment in recent:
            speaker = "–¢—ã" if segment.speaker == MessageRole.ASSISTANT else "–°–æ–±–µ—Å–µ–¥–Ω–∏–∫"
            context += f"\n{speaker}: {segment.text}"
        
        context += f"\n–°–æ–±–µ—Å–µ–¥–Ω–∏–∫: {user_message}\n–¢—ã:"
        
        return context
    
    def _build_moderation_prompt(self, conversation_text: str, current_prompt: str) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        return f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∏–∞–ª–æ–≥ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏, –Ω—É–∂–Ω–æ –ª–∏ —Å–º–µ–Ω–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é.

–¢–ï–ö–£–©–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø: {current_prompt}

–î–ò–ê–õ–û–ì:
{conversation_text}

–ü–†–ê–í–ò–õ–ê:
1. –ï—Å–ª–∏ —É–ø–æ–º—è–Ω—É—Ç–∞ —Å–æ–±–∞–∫–∞ ‚Üí —Å–º–µ–Ω–∏—Ç—å –Ω–∞ –ø—Ä–æ–º–ø—Ç –ø—Ä–æ —Ç–æ–≤–∞—Ä—ã –¥–ª—è —Å–æ–±–∞–∫
2. –ï—Å–ª–∏ —É–ø–æ–º—è–Ω—É—Ç—ã —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø—Ä–æ–±–ª–µ–º—ã ‚Üí —Å–º–µ–Ω–∏—Ç—å –Ω–∞ –ø—Ä–æ–º–ø—Ç –ø—Ä–æ –∑–∞—Ä–∞–±–æ—Ç–æ–∫
3. –ï—Å–ª–∏ —É–ø–æ–º—è–Ω—É—Ç—ã –¥–µ—Ç–∏ ‚Üí —Å–º–µ–Ω–∏—Ç—å –Ω–∞ –ø—Ä–æ–º–ø—Ç –ø—Ä–æ –¥–µ—Ç—Å–∫–∏–µ —Ç–æ–≤–∞—Ä—ã
4. –ï—Å–ª–∏ –¥—Ä—É–≥–∏–µ –∏–Ω—Ç–µ—Ä–µ—Å—ã ‚Üí —Å–º–µ–Ω–∏—Ç—å –Ω–∞ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø—Ä–æ–¥–∞—é—â–∏–π –ø—Ä–æ–º–ø—Ç

–û—Ç–≤–µ—Ç—å JSON:
{{
    "change_prompt": true/false,
    "new_prompt_type": "dog"|"money"|"children"|"sales"|null,
    "confidence": 0.0-1.0
}}"""
    
    def _extract_conversation_text(self, transcript_history: List[TranscriptSegment]) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏"""
        if not transcript_history:
            return ""
        
        recent = transcript_history[-20:] if len(transcript_history) > 20 else transcript_history
        lines = []
        
        for segment in recent:
            speaker = "–ö–ª–∏–µ–Ω—Ç" if segment.speaker.value == "user" else "AI"
            lines.append(f"{speaker}: {segment.text}")
        
        return "\n".join(lines)
    
    def _check_keywords(self, text: str, current_prompt: str) -> Optional[Dict[str, Any]]:
        """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
        text_lower = text.lower()
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–æ–º–ø—Ç—ã
        keyword_rules = {
            "dog": {
                "keywords": ["—Å–æ–±–∞–∫", "—â–µ–Ω–æ–∫", "–ø–µ—Å", "–ø—Å–∏–Ω"],
                "prompt": settings.dog_prompt,
                "reason": "–ö–ª–∏–µ–Ω—Ç —É–ø–æ–º—è–Ω—É–ª —Å–æ–±–∞–∫—É"
            },
            "money": {
                "keywords": ["–¥–µ–Ω–µ–≥ –Ω–µ—Ç", "–±–µ–∑ –¥–µ–Ω–µ–≥", "—Ñ–∏–Ω–∞–Ω—Å—ã –ø–ª–æ—Ö–æ"],
                "prompt": settings.money_prompt,
                "reason": "–ö–ª–∏–µ–Ω—Ç —É–ø–æ–º—è–Ω—É–ª —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø—Ä–æ–±–ª–µ–º—ã"
            },
            "children": {
                "keywords": ["–¥–µ—Ç–∏", "—Ä–µ–±–µ–Ω–æ–∫", "—Å—ã–Ω", "–¥–æ—á—å"],
                "prompt": settings.children_prompt,
                "reason": "–ö–ª–∏–µ–Ω—Ç —É–ø–æ–º—è–Ω—É–ª –¥–µ—Ç–µ–π"
            }
        }
        
        for rule_type, rule in keyword_rules.items():
            for keyword in rule["keywords"]:
                if keyword in text_lower and current_prompt != rule["prompt"]:
                    return {
                        "change_prompt": True,
                        "new_prompt": rule["prompt"],
                        "trigger_keywords": [keyword],
                        "trigger_reason": rule["reason"],
                        "confidence": 0.95
                    }
        
        return None
    
    def _parse_moderation_response(self, response: str) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏"""
        try:
            import json
            
            # –û—á–∏—â–∞–µ–º –æ—Ç markdown
            response = response.strip()
            if response.startswith("```"):
                response = response.split("```")[1]
                if response.startswith("json"):
                    response = response[4:]
            
            result = json.loads(response.strip())
            
            if result.get("change_prompt") and result.get("confidence", 0) > 0.8:
                # –ú–∞–ø–∏–º —Ç–∏–ø –ø—Ä–æ–º–ø—Ç–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç
                prompt_map = {
                    "dog": settings.dog_prompt,
                    "money": settings.money_prompt,
                    "children": settings.children_prompt,
                    "sales": settings.sales_prompt
                }
                
                prompt_type = result.get("new_prompt_type")
                if prompt_type and prompt_type in prompt_map:
                    return {
                        "change_prompt": True,
                        "new_prompt": prompt_map[prompt_type],
                        "trigger_reason": f"AI detected {prompt_type} context",
                        "confidence": result.get("confidence", 0.85)
                    }
            
        except Exception as e:
            self.logger.debug(f"Failed to parse moderation response: {e}")
        
        return None
    
    def _postprocess_dialogue_response(self, text: str) -> str:
        """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞"""
        # –£–¥–∞–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        text = text.replace("*", "").replace("_", "")
        text = text.replace("\n", " ").replace("\r", " ")
        
        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
        while "  " in text:
            text = text.replace("  ", " ")
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        sentences = text.split(". ")
        if len(sentences) > 2:
            text = ". ".join(sentences[:2]) + "."
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã
        for prefix in ["–¢—ã: ", "AI: ", "–û—Ç–≤–µ—Ç: "]:
            if text.startswith(prefix):
                text = text[len(prefix):].strip()
        
        return text.strip() or "–ü–æ–Ω—è—Ç–Ω–æ. –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ."
    
    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞"""
        try:
            test_response = await self._execute_with_fallback(
                self.dialogue_model,
                "–°–∫–∞–∂–∏ '—Ç–µ—Å—Ç' –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ",
                "health_check"
            )
            
            return test_response is not None and "—Ç–µ—Å—Ç" in test_response.lower()
            
        except Exception as e:
            self.logger.error(f"Health check failed: {e}")
            return False
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return {
            "current_model": self.model_name,
            "model_index": self.current_model_index,
            "available_models": len(self.WORKING_MODELS),
            "total_requests": self.request_count,
            "successful_requests": self.success_count,
            "success_rate": self.success_count / self.request_count if self.request_count > 0 else 0,
            "model_switches": self.model_switches,
            "last_switch_time": self.last_switch_time
        }